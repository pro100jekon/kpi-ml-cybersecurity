{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T12:20:37.450521Z",
     "start_time": "2024-12-23T12:20:36.468113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('spam.csv')\n",
    "df.head()"
   ],
   "id": "194b3b38b3c511ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T12:20:37.536416Z",
     "start_time": "2024-12-23T12:20:37.479742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df[['Message', 'Category']]\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Розділення на вхідні дані (x) та мітки класів (y)\n",
    "x = df['Message']\n",
    "y = LabelEncoder().fit_transform(df['Category'])\n",
    "\n",
    "# Розділення на тренувальну і тестову вибірки\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=47)\n",
    "\n",
    "# Перетворення тексту в числові вектори за допомогою TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "x_train_vec = vectorizer.fit_transform(x_train)\n",
    "x_test_vec = vectorizer.transform(x_test)"
   ],
   "id": "50f82501459c2a8c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T12:20:37.582783Z",
     "start_time": "2024-12-23T12:20:37.567652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(x_train_vec, y_train)\n",
    "\n",
    "# Прогнозування на тестовій вибірці\n",
    "y_pred = nb_classifier.predict(x_test_vec)\n",
    "\n",
    "# Оцінка точності та звіт по класифікації\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Точність: {accuracy:.2f}')\n",
    "\n",
    "# Детальний звіт\n",
    "print(classification_report(y_test, y_pred, target_names=['Spam', 'Ham']))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "d4fd734c4344c512",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точність: 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Spam       0.97      1.00      0.98       961\n",
      "         Ham       1.00      0.79      0.88       154\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.89      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "[[961   0]\n",
      " [ 33 121]]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Проблема нульової ймовірності виникає, коли ми намагаємось класифікувати слово, яке не з'являлося у навчальних даних для певного класу (Ham/Spam).",
   "id": "8517cc3b10e5b33e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T12:22:39.618220Z",
     "start_time": "2024-12-23T12:22:39.606680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ініціалізація наївного баєсівського класифікатора без Лапласового згладжування\n",
    "nb_classifier_no_smoothing = MultinomialNB(alpha=0.0, force_alpha=True)  # Без згладжування\n",
    "nb_classifier_no_smoothing.fit(x_train_vec, y_train)\n",
    "\n",
    "# Ініціалізація наївного баєсівського класифікатора з Лапласовим згладжуванням\n",
    "nb_classifier_with_smoothing = MultinomialNB(alpha=1.0)  # З згладжуванням\n",
    "nb_classifier_with_smoothing.fit(x_train_vec, y_train)\n",
    "\n",
    "# Нові коментарі для тестування\n",
    "new_comments = [\n",
    "    \"You should revise the task that was given to you\",\n",
    "    \"Free emails selling STRAIGHT UNDER YOUR WINDOW!\",\n",
    "]\n",
    "\n",
    "# Векторизуємо нові коментарі\n",
    "new_comments_vec = vectorizer.transform(new_comments)\n",
    "\n",
    "# Отримуємо передбачення та ймовірності без згладжування\n",
    "predictions_no_smoothing = nb_classifier_no_smoothing.predict(new_comments_vec)\n",
    "probabilities_no_smoothing = nb_classifier_no_smoothing.predict_proba(new_comments_vec)\n",
    "\n",
    "# Отримуємо передбачення та ймовірності із згладжуванням\n",
    "predictions_with_smoothing = nb_classifier_with_smoothing.predict(new_comments_vec)\n",
    "probabilities_with_smoothing = nb_classifier_with_smoothing.predict_proba(new_comments_vec)\n",
    "\n",
    "# Виводимо результати\n",
    "print(\"Результати без згладжування Лапласа:\")\n",
    "for comment, prediction, prob in zip(new_comments, predictions_no_smoothing, probabilities_no_smoothing):\n",
    "    print(f\"Коментар: {comment} \\n   -> Результат фільтрації: {prediction} ({'Spam' if prediction == 1 else 'Ham'})\")\n",
    "    print(f\"   -> Ймовірності: Ham: {prob[0]:.4f}, Spam: {prob[1]:.4f}\\n\")\n",
    "\n",
    "print(\"Результати з згладжуванням Лапласа:\")\n",
    "for comment, prediction, prob in zip(new_comments, predictions_with_smoothing, probabilities_with_smoothing):\n",
    "    print(f\"Коментар: {comment} \\n   -> Результат фільтрації: {prediction} ({'Spam' if prediction == 1 else 'Ham'})\")\n",
    "    print(f\"   -> Ймовірності: Ham: {prob[0]:.4f}, Spam: {prob[1]:.4f}\\n\")"
   ],
   "id": "3cebd21ce568c010",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результати без згладжування Лапласа:\n",
      "Коментар: You should revise the task that was given to you \n",
      "   -> Результат фільтрації: 0 (Ham)\n",
      "   -> Ймовірності: Ham: 1.0000, Spam: 0.0000\n",
      "\n",
      "Коментар: Free emails selling STRAIGHT UNDER YOUR WINDOW! \n",
      "   -> Результат фільтрації: 0 (Ham)\n",
      "   -> Ймовірності: Ham: 1.0000, Spam: 0.0000\n",
      "\n",
      "Результати з згладжуванням Лапласа:\n",
      "Коментар: You should revise the task that was given to you \n",
      "   -> Результат фільтрації: 0 (Ham)\n",
      "   -> Ймовірності: Ham: 0.8514, Spam: 0.1486\n",
      "\n",
      "Коментар: Free emails selling STRAIGHT UNDER YOUR WINDOW! \n",
      "   -> Результат фільтрації: 0 (Ham)\n",
      "   -> Ймовірності: Ham: 0.8127, Spam: 0.1873\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yevhenii/.local/lib/python3.10/site-packages/sklearn/naive_bayes.py:897: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### При запуску коду без згладжування Лапласа ми можемо спостерігати, що модель класифікує деякі коментарі як \"Ham\" або \"Spam\" з ймовірностями, які можуть бути 0 для одного з класів. Це ілюструє проблему нульової ймовірності: якщо модель не бачила певне слово під час навчання, вона не може надати йому жодної ймовірності.\n",
    "\n",
    "## Висновки\n",
    "### Після виконання коду, результати для двох класифікаторів (згладжування і без) продемонструють різницю:\n",
    "\n",
    "### Без згладжування деякі коментарі матимуть ймовірності 0 для одного з класів, що свідчить про проблему нульової ймовірності. А зі згладжуванням модель надає ненульові ймовірності, навіть якщо слова відсутні в навчальних даних, що дозволяє уникнути проблеми нульової ймовірності."
   ],
   "id": "9112ccb1c2451966"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
